{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAr7S00ktFePQ6jFVuzCT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariyselita/CIP/blob/main/Algoritmos_de_clasificaci%C3%B3n_TAREA_9_CIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxYmuss6pJqQ",
        "outputId": "3285d9a6-f9f2-4036-c35e-db7328333f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/drive/My Drive/CIP/Datos/'"
      ],
      "metadata": {
        "id": "EfJ_2PX6pNpi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Cargar los datasets\n",
        "ciclones_df = pd.read_csv(filepath + 'Ciclones.csv')\n",
        "clima_extremo_df = pd.read_csv(filepath + 'Clima_Extremo.csv')\n",
        "incendios_forestales_df = pd.read_csv(filepath + 'Incendios_Forestales.csv')\n",
        "sequias_df = pd.read_csv(filepath + 'Sequías.csv')\n",
        "sismos_df = pd.read_csv(filepath + 'Sismos.csv')\n",
        "\n",
        "# Función para balancear los datasets\n",
        "def balance_dataset(df, class_name):\n",
        "    df['Clase'] = class_name\n",
        "    majority_count = df['Clase'].value_counts().max()\n",
        "\n",
        "    balanced_df = pd.DataFrame()\n",
        "\n",
        "    for label in df['Clase'].unique():\n",
        "        df_label = df[df['Clase'] == label]\n",
        "        if len(df_label) < majority_count:\n",
        "            df_label = resample(df_label, replace=True, n_samples=majority_count, random_state=42)\n",
        "        balanced_df = pd.concat([balanced_df, df_label])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# Agregar columna 'Clase' y balancear los datasets\n",
        "datasets_balanced = {\n",
        "    \"Ciclones\": balance_dataset(ciclones_df, 'Ciclones'),\n",
        "    \"Clima Extremo\": balance_dataset(clima_extremo_df, 'Clima Extremo'),\n",
        "    \"Incendios Forestales\": balance_dataset(incendios_forestales_df, 'Incendios Forestales'),\n",
        "    \"Sequías\": balance_dataset(sequias_df, 'Sequías'),\n",
        "    \"Sismos\": sismos_df[sismos_df['Magnitud'] >= 3.5].assign(Clase='Sismos')\n",
        "}\n",
        "\n",
        "# Determinar el tamaño del dataset más pequeño después del filtrado\n",
        "min_size = min([len(df) for df in datasets_balanced.values()])\n",
        "\n",
        "# Balancear todos los datasets al tamaño mínimo\n",
        "balanced_datasets_final = {\n",
        "    name: resample(df, replace=False, n_samples=min_size, random_state=42) for name, df in datasets_balanced.items()\n",
        "}\n",
        "\n",
        "# Guardar los datasets balanceados en archivos CSV\n",
        "for name, df in balanced_datasets_final.items():\n",
        "    df.to_csv(filepath + f'balanced_{name}.csv', index=False)\n",
        "\n",
        "# Mostrar la distribución de clases en los datasets balanceados finales\n",
        "for name, df in balanced_datasets_final.items():\n",
        "    print(f\"Dataset: {name}\")\n",
        "    print(df['Clase'].value_counts())\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP0uRtA7pfvK",
        "outputId": "b98b424c-d69b-4c6a-8e60-fe2bc71fbd77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Ciclones\n",
            "Clase\n",
            "Ciclones    291\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Dataset: Clima Extremo\n",
            "Clase\n",
            "Clima Extremo    291\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Dataset: Incendios Forestales\n",
            "Clase\n",
            "Incendios Forestales    291\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Dataset: Sequías\n",
            "Clase\n",
            "Sequías    291\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Dataset: Sismos\n",
            "Clase\n",
            "Sismos    291\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "aWzN1uXvq30w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ciclones = pd.read_csv(filepath + 'balanced_Ciclones.csv')\n",
        "df_clima_extremo = pd.read_csv(filepath + 'balanced_Clima Extremo.csv')\n",
        "df_incendios_forestales = pd.read_csv(filepath + 'balanced_Incendios Forestales.csv')\n",
        "df_sequías = pd.read_csv(filepath + 'balanced_Sequías.csv')\n",
        "df_sismos = pd.read_csv(filepath + 'balanced_Sismos.csv')\n",
        "\n",
        "# Añadir una columna de clase específica para cada dataset\n",
        "df_ciclones['Clase'] = 'Ciclones'\n",
        "df_clima_extremo['Clase'] = 'Clima Extremo'\n",
        "df_incendios_forestales['Clase'] = 'Incendios Forestales'\n",
        "df_sequías['Clase'] = 'Sequías'\n",
        "df_sismos['Clase'] = 'Sismos'\n",
        "\n",
        "# Eliminar la columna 'Fecha' si existe\n",
        "for df in [df_ciclones, df_clima_extremo, df_incendios_forestales, df_sequías, df_sismos]:\n",
        "    if 'Fecha' in df.columns:\n",
        "        df.drop(columns=['Fecha'], inplace=True)\n",
        "\n",
        "# Combinar los datasets en un solo dataframe\n",
        "df = pd.concat([df_ciclones, df_clima_extremo, df_incendios_forestales, df_sequías, df_sismos], ignore_index=True)\n",
        "\n",
        "# Eliminar filas con valores NaN en las características que vamos a usar\n",
        "features = ['Ubicación', 'Magnitud', 'Duración', 'Áreas Afectadas']\n",
        "features = [f for f in features if f in df.columns]\n",
        "df = df.dropna(subset=features)\n",
        "\n",
        "# Verificar la distribución de la clase\n",
        "print(df['Clase'].value_counts())\n",
        "\n",
        "# Seleccionar características y etiquetas\n",
        "X = df[features]\n",
        "y = df['Clase']  # Asegurarse de que la columna de etiquetas sea 'Clase'\n",
        "\n",
        "# Convertir características categóricas a numéricas\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xicGPyrssO_n",
        "outputId": "7413c394-0e35-4d2f-8566-ae0dd8cf4d35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase\n",
            "Sismos    291\n",
            "Name: count, dtype: int64\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Sismos       1.00      1.00      1.00        59\n",
            "\n",
            "    accuracy                           1.00        59\n",
            "   macro avg       1.00      1.00      1.00        59\n",
            "weighted avg       1.00      1.00      1.00        59\n",
            "\n"
          ]
        }
      ]
    }
  ]
}